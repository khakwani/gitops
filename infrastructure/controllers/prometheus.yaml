# Namespace creation for monitoring
apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
  labels:
    app.kubernetes.io/component: monitoring
---
# Helm repository for Prometheus
apiVersion: source.toolkit.fluxcd.io/v1
kind: HelmRepository
metadata:
  name: prometheus-community
  namespace: monitoring
spec:
  interval: 12h
  type: oci
  url: oci://ghcr.io/prometheus-community/charts
---
# Helm repository for Grafana Loki
apiVersion: source.toolkit.fluxcd.io/v1
kind: HelmRepository
metadata:
  name: grafana
  namespace: monitoring
spec:
  interval: 12h
  url: https://grafana.github.io/helm-charts
---
# Helm release for kube-prometheus-stack
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
  namespace: monitoring
spec:
  interval: 1h
  chart:
    spec:
      chart: kube-prometheus-stack
      version: "58.7.2"
      sourceRef:
        kind: HelmRepository
        name: prometheus-community
      interval: 1h
  values:
    alertmanager:
      enabled: true
      alertmanagerSpec:
        config:
          global:
            resolve_timeout: 5m
          route:
            group_by: ['alertname', 'job']
            group_wait: 30s
            group_interval: 5m
            repeat_interval: 5m
            receiver: 'null'
            routes:
              - match:
                  alertname: Watchdog
                receiver: 'null'
          receivers:
            - name: 'null'
    prometheus:
      prometheusSpec:
        storageSpec:
          volumeClaimTemplate:
            spec:
              accessModes: ["ReadWriteOnce"]
              resources:
                requests:
                  storage: 10Gi
        alerting:
          alertmanagers:
            - static_configs:
                - targets:
                    - 'kube-prometheus-stack-alertmanager.monitoring:9093'
      nodeSelector:
        kubernetes.io/hostname: staging-worker
      tolerations:
        - key: "node-role.kubernetes.io/worker"
          operator: "Exists"
          effect: "NoSchedule"
      retention: 24h
      resources:
        limits:
          cpu: 2
          memory: 1Gi
        requests:
          cpu: 500m
          memory: 500Mi
      podMonitorNamespaceSelector:
        any: true
      podMonitorSelector: {}
      podMonitorSelectorNilUsesHelmValues: false
      ruleNamespaceSelector:
        any: true
      ruleSelector: {}
      ruleSelectorNilUsesHelmValues: false
      serviceMonitorNamespaceSelector:
        matchNames:
          - monitoring
      serviceMonitorSelector: {}
      serviceMonitorSelectorNilUsesHelmValues: false
      probeNamespaceSelector:
        any: true
      probeSelector: {}
      probeSelectorNilUsesHelmValues: false
---
# Helm release for Loki Stack
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: loki-stack
  namespace: monitoring
spec:
  interval: 1h
  chart:
    spec:
      chart: loki-stack
      version: "2.9.11"
      sourceRef:
        kind: HelmRepository
        name: grafana
      interval: 1h
  values:
    loki:
      enabled: true
      persistence:
        enabled: true
        storageClassName: standard
        size: 10Gi
      config:
        auth_enabled: false
        server:
          http_listen_port: 3100
        ingester:
          lifecycler:
            address: 127.0.0.1
            ring:
              kvstore:
                store: inmemory
              replication_factor: 1
        schema_config:
          configs:
            - from: 2020-10-24
              store: boltdb-shipper
              object_store: filesystem
              schema: v11
              index:
                prefix: index_
                period: 24h
        storage_config:
          boltdb_shipper:
            active_index_directory: /data/loki/index
            cache_location: /data/loki/cache
            shared_store: filesystem
          filesystem:
            directory: /data/loki/chunks
        limits_config:
          enforce_metric_name: false
          reject_old_samples: true
          reject_old_samples_max_age: 168h
        chunk_store_config:
          max_look_back_period: 0s
        table_manager:
          retention_deletes_enabled: true
          retention_period: 336h
    promtail:
      enabled: true
      config:
        logLevel: info
        serverPort: 3101
        clients:
          - url: http://loki-stack:3100/loki/api/v1/push
        positions:
          filename: /run/promtail/positions.yaml
        scrape_configs:
          - job_name: kubernetes-pods
            kubernetes_sd_configs:
              - role: pod
            relabel_configs:
              - source_labels: [__meta_kubernetes_pod_controller_name]
                target_label: _service_
              - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name]
                target_label: app
              - source_labels: [__meta_kubernetes_pod_node_name]
                target_label: node_name
              - source_labels: [__meta_kubernetes_namespace]
                target_label: namespace
              - source_labels: [__meta_kubernetes_pod_name]
                target_label: pod
              - source_labels: [__meta_kubernetes_pod_container_name]
                target_label: container
          - job_name: kubernetes-pods-static
            kubernetes_sd_configs:
              - role: pod
            relabel_configs:
              - source_labels: [__meta_kubernetes_pod_annotation_kubernetes_io_config_mirror]
                action: keep
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                action: keep
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
                action: replace
                target_label: _metrics_path_
                regex: (.+)
      serviceMonitor:
        enabled: true
---
# Promtail DaemonSet
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: promtail-daemonset
  namespace: monitoring
spec:
  selector:
    matchLabels:
      name: promtail
  template:
    metadata:
      labels:
        name: promtail
    spec:
      serviceAccountName: promtail-serviceaccount
      containers:
        - name: promtail-container
          image: grafana/promtail
          args:
            - -config.file=/etc/promtail/promtail.yaml
          env:
            - name: 'HOSTNAME'
              valueFrom:
                fieldRef:
                  fieldPath: 'spec.nodeName'
          volumeMounts:
            - name: logs
              mountPath: /var/log
            - name: promtail-config
              mountPath: /etc/promtail
            - mountPath: /var/lib/docker/containers
              name: varlibdockercontainers
              readOnly: true
      volumes:
        - name: logs
          hostPath:
            path: /var/log
        - name: varlibdockercontainers
          hostPath:
            path: /var/lib/docker/containers
        - name: promtail-config
          configMap:
            name: promtail-config
---
# Promtail ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: monitoring
data:
  promtail.yaml: |
    server:
      http_listen_port: 9080
      grpc_listen_port: 0

    clients:
      - url: http://loki-stack:3100/loki/api/v1/push

    positions:
      filename: /tmp/positions.yaml

    scrape_configs:
      - job_name: pod-logs
        kubernetes_sd_configs:
          - role: pod
        pipeline_stages:
          - docker: {}
        relabel_configs:
          - source_labels:
              - __meta_kubernetes_pod_node_name
            target_label: __host__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - action: replace
            replacement: $1
            separator: /
            source_labels:
              - __meta_kubernetes_namespace
              - __meta_kubernetes_pod_name
            target_label: job
          - action: replace
            source_labels:
              - __meta_kubernetes_namespace
            target_label: namespace
          - action: replace
            source_labels:
              - __meta_kubernetes_pod_name
            target_label: pod
          - action: replace
            source_labels:
              - __meta_kubernetes_pod_container_name
            target_label: container
          - replacement: /var/log/pods/*$1/*.log
            separator: /
            source_labels:
              - __meta_kubernetes_pod_uid
              - __meta_kubernetes_pod_container_name
            target_label: __path__
---
# ServiceAccount for Promtail
apiVersion: v1
kind: ServiceAccount
metadata:
  name: promtail-serviceaccount
  namespace: monitoring
---
# RBAC for Promtail
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: promtail-clusterrole
rules:
  - apiGroups: [""]
    resources:
      - nodes
      - services
      - pods
    verbs:
      - get
      - watch
      - list
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: promtail-clusterrolebinding
subjects:
  - kind: ServiceAccount
    name: promtail-serviceaccount
    namespace: monitoring
roleRef:
  kind: ClusterRole
  name: promtail-clusterrole
  apiGroup: rbac.authorization.k8s.io
